using Test
using BeautifulAlgorithms


@testset "Gradient Descent" begin
    using Statistics
    using LinearAlgebra

    mutable struct Decay i end
    Base.:*(Î´Î·::Decay, x) = x/sqrt(Î´Î·.i+=1)

    loss_squared(x, y, ğ°, Ï†) = (ğ°â‹…Ï†(x) - y)^2
    mean_loss(ğ°, ğ’Ÿtrain, Ï†, loss) = mean(loss(x, y, ğ°, Ï†) for (x,y) âˆˆ ğ’Ÿtrain)

    """
    Single-dimensional training input data.
    """
    function test_gradient_descent()
        ğ’Ÿtrain = [(3,4), (-1,3), (-1,0)]
        ğ°_opt = gradient_descent(ğ’Ÿtrain, x->x)
        y_opt = mean_loss(ğ°_opt, ğ’Ÿtrain, x->x, loss_squared)
        return (ğ°_opt, y_opt)
    end

    """
    Decay learning rate Î·.
    """
    function test_gradient_descent_decay(T)
        # Decay learning rate
        ğ’Ÿtrain = [(3,4), (-1,3), (-1,0)]
        ğ°_opt = gradient_descent(ğ’Ÿtrain, x->x; Î·=Decay(0), T=T)
        y_opt = mean_loss(ğ°_opt, ğ’Ÿtrain, x->x, loss_squared)
        return (ğ°_opt, y_opt)
    end

    """
    Multi-dimensional training data input.
    """
    function test_gradient_descent_multi()
        ğ’Ÿtrain = [([3,0.7],4), ([-1,0.3],3), ([-1,-3],0)]
        ğ°_opt = gradient_descent(ğ’Ÿtrain, x->x)
        y_opt = mean_loss(ğ°_opt, ğ’Ÿtrain, x->x, loss_squared)
        return (ğ°_opt, y_opt)
    end

    ğ°, y = test_gradient_descent()
    @test ğ° â‰ˆ [0.8181818181818182]
    @test y â‰ˆ 5.878787878787879

    ğ°, y = test_gradient_descent_decay(30)
    @test ğ° â‰ˆ [0.41794205540127405]
    @test y â‰ˆ 6.466158060393507

    ğ°, y = test_gradient_descent_multi()
    @test ğ° â‰ˆ [0.8314306533883896, -0.03036191401505953]
    @test y â‰ˆ 5.876487733786738
end


@testset "Stochastic Gradeient Descent" begin
    Base.:*(Î´Î·::Decay, x) = x/sqrt(Î´Î·.i+=1)

    loss_squared(x, y, ğ°, Ï†) = (ğ°â‹…Ï†(x) - y)^2
    mean_loss(ğ°, ğ’Ÿtrain, Ï†, loss) = mean(loss(x, y, ğ°, Ï†) for (x,y) âˆˆ ğ’Ÿtrain)

    function test_stochastic_gradient_descent()
        ğ’Ÿtrain = [([3,0.7],4), ([-1,0.3],3), ([-1,-3],0)]
        ğ°_opt = stochastic_gradient_descent(ğ’Ÿtrain, x->x; Î·=0.01)
        y_opt = mean_loss(ğ°_opt, ğ’Ÿtrain, x->x, loss_squared)
        return (ğ°_opt, y_opt)
    end

    ğ°, y = test_stochastic_gradient_descent()

    @test ğ° â‰ˆ [0.8286227687981166, -0.07376395387093937]
    @test y â‰ˆ 5.882922020275335
end


@testset "One-Layer Neural Network" begin
    function test_neural_network(g=Ïƒ)
        x = 2
        Ï† = x -> [x, x^2, sqrt(abs(x))]
        ğ• = [[2,-1,3], [3,0,1]]
        ğ° = [+1, -1]
        neural_network(x, ğ•, ğ°, Ï†, g)
    end

    @test test_neural_network(Ïƒ) â‰ˆ -0.013563772681566943
    @test test_neural_network(ReLU) â‰ˆ -3.1715728752538093

    @test Ïƒ(0) == 0.5
    @test ReLU(1) == 1
    @test ReLU(-1) == 0
end


@testset "Nearest Neighbor" begin
    function test_nearest_neighbor()
        ğ’Ÿtrain = [([5,9],6),
                  ([5,5],7),
                  ([7,5],8),
                  ([9,9],10)]
        Ï† = x->x

        points = [[6.1,6.5], [9,6.5]]

        neighbor_manhattan = [nearest_neighbor(p, Ï†, ğ’Ÿtrain, dist_manhattan) for p in points]
        @test neighbor_manhattan == [8, 10]

        neighbor_euclidean = [nearest_neighbor(p, Ï†, ğ’Ÿtrain, dist_euclidean) for p in points]
        @test neighbor_euclidean == [8, 8]

        neighbor_supremum = [nearest_neighbor(p, Ï†, ğ’Ÿtrain, dist_supremum) for p in points]
        @test neighbor_supremum == [7, 8]

        @test nearest_neighbor(0, x->x, [(0,0)], dist_manhattan) == 0
        @test dist_manhattan([0,0], [3,3]) == 6.0
        @test dist_euclidean([0,0], [3,3]) â‰ˆ 4.242640687119285
        @test dist_supremum([0,0], [3,3]) == 3.0
    end

    test_nearest_neighbor()
end


@testset "Cross-Entropy Method" begin
    using Distributions
    import Random: seed!
    import LinearAlgebra: norm
    seed!(0)
    f = x->norm(x)
    Î¼ = [0.5, 1.5]
    Î£ = [1.0 0.2; 0.2 2.0]
    P = MvNormal(Î¼, Î£)
    k_max = 10
    P = cross_entropy_method(f, P, k_max)

    @test isapprox(P.Î¼, [-6.13623e-7, -1.37216e-6], atol=1e-5)
end


@testset "Value Iteration" begin
    P = MDP(0.95, [1:100;], [+1, -1], (s,a,sâ€²)->s + a == sâ€² ? 0.7 : 0, (s,a)->s == 50 ? 1 : 0)

    U = value_iteration(P, 100)

    reshape(U, 10, 10)

    # Optimal policy (ğ’œ = [+1, -1])
    @test all(policy.(1:50, ğ’«=P, U=U) .== 1) # go forwards toward 50
    @test all(policy.(51:100, ğ’«=P, U=U) .== 2) # go backwards toward 50
end


@testset "Monte Carlo Tree Search" begin
    import Random: seed!
    seed!(0)

    ğ’® = [1:100;]
    ğ’œ = [+1, -1]
    T = (s,a,sâ€²)->s + a == sâ€² ? 0.7 : 0
    R = (s,a)->s == 50 ? 1 : 0
    G = (s, a)-> begin
        sâ€² = rand([s, s+a, s-a])
        r = R(s, a)
        return (sâ€², r)
    end
    P = MDPáµ£(0.95, ğ’®, ğ’œ, T, R, G)

    mcts = MonteCarloTreeSearch(P, Dict(), Dict(), 50, 1000, 1, s->rand(map(a->s+a, ğ’œ)))

    @test mcts(1) == 1
    @test mcts(55) == 2
    @test mcts(100) == 1
end
