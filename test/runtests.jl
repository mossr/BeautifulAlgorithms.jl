using Test
using BeautifulAlgorithms


@testset "Cross-Entropy Method" begin
    using Distributions
    import Random: seed!
    import LinearAlgebra: norm
    seed!(0)
    f = x->norm(x)
    Î¼ = [0.5, 1.5]
    Î£ = [1.0 0.2; 0.2 2.0]
    P = MvNormal(Î¼, Î£)
    k_max = 10
    P = cross_entropy_method(f, P, k_max)

    @test isapprox(P.Î¼, [-6.13623e-7, -1.37216e-6], atol=1e-5)
end


@testset "Value Iteration" begin
    P = MDP(0.95, [1:100;], [+1, -1], (s,a,sâ€²)->s + a == sâ€² ? 0.7 : 0, (s,a)->s == 50 ? 1 : 0)

    U = value_iteration(P, 100)

    reshape(U, 10, 10)

    # Optimal policy (ğ’œ = [+1, -1])
    @test all(policy.(1:50, ğ’«=P, U=U) .== 1) # go forwards toward 50
    @test all(policy.(51:100, ğ’«=P, U=U) .== 2) # go backwards toward 50
end


@testset "Monte Carlo Tree Search" begin
    import Random: seed!
    seed!(0)

    ğ’® = [1:100;]
    ğ’œ = [+1, -1]
    T = (s,a,sâ€²)->s + a == sâ€² ? 0.7 : 0
    R = (s,a)->s == 50 ? 1 : 0
    G = (s, a)-> begin
        sâ€² = rand([s, s+a, s-a])
        r = R(s, a)
        return (sâ€², r)
    end
    P = MDPG(0.95, ğ’®, ğ’œ, T, R, G)

    mcts = MonteCarloTreeSearch(P, Dict(), Dict(), 50, 1000, 1, s->rand(map(a->s+a, ğ’œ)))

    @test mcts(1) == 1
    @test mcts(55) == 2
    @test mcts(100) == 1
end
