@testset "Stochastic gradeient descent" begin
    Base.:*(Î´Î·::Decay, x) = x/sqrt(Î´Î·.i+=1)

    loss_squared(x, y, ğ°, Ï†) = (ğ°â‹…Ï†(x) - y)^2
    mean_loss(ğ°, ğ’Ÿtrain, Ï†, loss) = mean(loss(x, y, ğ°, Ï†) for (x,y) âˆˆ ğ’Ÿtrain)

    function test_stochastic_gradient_descent()
        ğ’Ÿtrain = [([3,0.7],4), ([-1,0.3],3), ([-1,-3],0)]
        ğ°_opt = stochastic_gradient_descent(ğ’Ÿtrain, x->x, âˆ‡loss_squared; Î·=0.01)
        y_opt = mean_loss(ğ°_opt, ğ’Ÿtrain, x->x, loss_squared)
        return (ğ°_opt, y_opt)
    end

    ğ°, y = test_stochastic_gradient_descent()

    @test ğ° â‰ˆ [0.8286227687981166, -0.07376395387093937]
    @test y â‰ˆ 5.882922020275335
end
